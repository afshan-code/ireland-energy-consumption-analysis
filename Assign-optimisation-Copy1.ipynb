{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318fb711-22eb-41c8-9b1d-142147b42b3b",
   "metadata": {},
   "source": [
    "I will be applying optimization in different areas:\n",
    "1. Optimization of memory usage by loading data in chunks\n",
    "2. Optimization by data types\n",
    "3. Optimization of time, memory usage and CPU usage while applying machine learning models on my dataset taken from csv file (GridSeachCV and Cross-Validation part).\n",
    "   Apart from this, I will apply cross validation with cv=5,10,15 also to check the optimized results.\n",
    "   Lastly, I will check the optimized execution time with different no of CPU processors used. \n",
    "Justification: The reason for applying optimization in machine learning parts is that these sections of code require exhaustive search and computation, thus taking a lot of time and memory, that need to be optimised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15d7a02b-e608-4fab-b495-67272011df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "%matplotlib inline \n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from scipy.stats import skew,kurtosis\n",
    "from scipy.stats import poisson,norm\n",
    "sns.set(color_codes=True)\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import threading \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724c38a-eb32-4c69-b0c1-2a54d622fe91",
   "metadata": {},
   "source": [
    "# DATA PREPARATION AND VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50795883-d685-407b-9a61-6ead26fc9a00",
   "metadata": {},
   "source": [
    "## EXPLORATORY DATA ANALYSIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d5678adc-e27b-4259-aef7-146d801a4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Energy2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d5b0ac1-45f5-4072-8747-15d65f6a2121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic Label</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Sum of all coal products</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Bituminous coal</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Anthracite and manufactured ovoids</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Coke</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Lignite</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Statistic Label                    Sector  Year  \\\n",
       "0  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "1  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "2  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "3  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "4  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "\n",
       "                            Fuel Type  UNIT  VALUE  \n",
       "0            Sum of all coal products  ktoe    843  \n",
       "1                     Bituminous coal  ktoe    825  \n",
       "2  Anthracite and manufactured ovoids  ktoe      0  \n",
       "3                                Coke  ktoe      0  \n",
       "4                             Lignite  ktoe     18  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d26b9-253b-4cd4-a1d9-60934830bba1",
   "metadata": {},
   "source": [
    "# 1. Optimization of memory usage by loading data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c796b4e4-49df-48c3-8847-4640ce070329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "57e8985f-7b50-4210-9e36-d1d02c3319a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage when loading the full dataset:\n",
      "Max memory used (full load): 74.87109375 MiB\n",
      "\n",
      "Memory usage when loading the dataset in chunks:\n",
      "Max memory used (chunked load): 65.5546875 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Function to load the entire dataset\n",
    "def load_full_data():\n",
    "    #df = pd.read_csv('energy_data.csv')\n",
    "    df=pd.read_csv(\"Energy2.csv\")# Load the whole dataset at once\n",
    "    return df\n",
    "\n",
    "# Function to load the data in chunks and process it\n",
    "def load_data_in_chunks(chunksize=10000):\n",
    "    for chunk in pd.read_csv('Energy2.csv', chunksize=chunksize):\n",
    "        process(chunk)  # Process each chunk\n",
    "\n",
    "# Simulate processing function for chunks\n",
    "def process(chunk):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Use memory_profiler to track memory usage for the full load\n",
    "def profile_full_load():\n",
    "    mem_usage = memory_usage((load_full_data,))  # Measure memory usage when loading full data\n",
    "    return mem_usage\n",
    "\n",
    "# Use memory_profiler to track memory usage for chunked loading\n",
    "def profile_chunked_load(chunksize=10000):\n",
    "    mem_usage = memory_usage((load_data_in_chunks, (chunksize,)))  # Measure memory usage when loading data in chunks\n",
    "    return mem_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Profile memory usage when loading the full dataset\n",
    "    print(\"Memory usage when loading the full dataset:\")\n",
    "    full_load_mem_usage = profile_full_load()\n",
    "    print(f\"Max memory used (full load): {max(full_load_mem_usage)} MiB\\n\")\n",
    "    \n",
    "    # Profile memory usage when loading the dataset in chunks\n",
    "    print(\"Memory usage when loading the dataset in chunks:\")\n",
    "    chunked_load_mem_usage = profile_chunked_load()\n",
    "    print(f\"Max memory used (chunked load): {max(chunked_load_mem_usage)} MiB\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8d02d-f3ed-4770-9347-5668c9a547d7",
   "metadata": {},
   "source": [
    "Insights: The above results show a clear decrease in memory usage when data is loaded in chunks as compared to loading the full dataset all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18eb170-91b3-404e-99cf-ffd624fb0149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d784f8d-3e12-425b-8837-39f241e7160f",
   "metadata": {},
   "source": [
    "# 2. Optimization by data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd789540-c850-4ae1-bb44-1dfe5bc31572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65340 entries, 0 to 65339\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Statistic Label  65340 non-null  object\n",
      " 1   Sector           65340 non-null  object\n",
      " 2   Year             65340 non-null  int64 \n",
      " 3   Fuel Type        65340 non-null  object\n",
      " 4   UNIT             65340 non-null  object\n",
      " 5   VALUE            65340 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 17.8 MB\n"
     ]
    }
   ],
   "source": [
    "#We look at memory usage in by the daat types and variable in our original dataset\n",
    "df.info(memory_usage='deep')\n",
    "#Gives basic info about your DataFrame df and also shows a more accurate estimate of memory usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264fcf6f-cc24-42dc-95ba-6922e7a72a0f",
   "metadata": {},
   "source": [
    "Here we can see that Statistic Label, Sector, Fuel Type and UNIT have object data type. Since object type takes more memory therefore we can down cast our data type to category, which requires less memory.\n",
    "Similarly, Year and VALUE have data type int64. This again requires more memory so we can down cast our data type to int16, which requires less memory. We can do this because every year has four digits and it is an 11 bit number and int16 is sufficient to store an 11-bit number. Similarly, the VALUE column has a maximum value 13189, which comprises 5 digits and comes out to be a 14 bit number. Here, also, int16 is sufficient to store a 14-bit number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e860ee6-596f-4548-aa9f-ce8a37c1f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before optimization: 17.84 MiB\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage before optimization\n",
    "mem_before = df.memory_usage(deep=True).sum() / 1024**2  # in MiB\n",
    "print(f\"Memory usage before optimization: {mem_before:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83455ae9-6db3-49f8-8941-96ab3635d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic Label    category\n",
      "Sector             category\n",
      "Year                  int16\n",
      "Fuel Type          category\n",
      "UNIT               category\n",
      "VALUE                 int16\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Optimize data types\n",
    "# Convert object columns to category if they have few unique values\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    num_unique = df[col].nunique()\n",
    "    num_total = len(df[col])\n",
    "    if num_unique / num_total < 0.5:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Downcast integers\n",
    "df['Year'] = pd.to_numeric(df['Year'], downcast='integer')\n",
    "df['VALUE'] = pd.to_numeric(df['VALUE'], downcast='integer')\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93dbfc95-6e42-4ba8-b0f8-7436fb9f1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 0.51 MiB\n",
      "Memory saved: 17.33 MiB\n"
     ]
    }
   ],
   "source": [
    "#Optimized memory usage\n",
    "mem_after = df.memory_usage(deep=True).sum() / 1024**2  # in MiB\n",
    "print(f\"Memory usage after optimization: {mem_after:.2f} MiB\")\n",
    "print(f\"Memory saved: {mem_before - mem_after:.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5093e17-d1bd-4dd3-be4f-ac59833ce536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65340 entries, 0 to 65339\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Statistic Label  65340 non-null  category\n",
      " 1   Sector           65340 non-null  category\n",
      " 2   Year             65340 non-null  int16   \n",
      " 3   Fuel Type        65340 non-null  category\n",
      " 4   UNIT             65340 non-null  category\n",
      " 5   VALUE            65340 non-null  int16   \n",
      "dtypes: category(4), int16(2)\n",
      "memory usage: 519.3 KB\n"
     ]
    }
   ],
   "source": [
    "df['Year'] = pd.to_numeric(df['Year'], downcast='integer')\n",
    "df['VALUE'] = pd.to_numeric(df['VALUE'], downcast='integer')\n",
    "\n",
    "for col in ['Statistic Label', 'Sector', 'Fuel Type', 'UNIT']:\n",
    "    df[col] = df[col].astype('category')\n",
    "    \n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6f464-6cb5-47e6-a830-38ff5cce4b47",
   "metadata": {},
   "source": [
    "Insights: The above working shows clearly that as we downcast the data types, memory usage gets reduced significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997b0a9-f0ee-4450-8249-b0467aa83718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8fe8355-2762-46a7-bf6f-f28246b5fa35",
   "metadata": {},
   "source": [
    "# 3. Optimization of time, memory usage and CPU usage while applying machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68faa1c-08e0-4514-9a96-8c27ef611743",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16c49d4a-cdb6-4201-a33b-7b6bc2d4f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Energy2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de33c866-1dd3-41b5-b5e0-9a0742e65d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic Label</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Sum of all coal products</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Bituminous coal</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Anthracite and manufactured ovoids</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Coke</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Final energy consumption</td>\n",
       "      <td>1990</td>\n",
       "      <td>Lignite</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Statistic Label                    Sector  Year  \\\n",
       "0  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "1  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "2  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "3  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "4  Fuel Consumption (ktoe)  Final energy consumption  1990   \n",
       "\n",
       "                            Fuel Type  UNIT  VALUE  \n",
       "0            Sum of all coal products  ktoe    843  \n",
       "1                     Bituminous coal  ktoe    825  \n",
       "2  Anthracite and manufactured ovoids  ktoe      0  \n",
       "3                                Coke  ktoe      0  \n",
       "4                             Lignite  ktoe     18  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf1ad8-4481-485b-a009-7b14e642ae26",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0872ebb9-df21-4b8e-aa30-3a0fe11ec960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.metrics import mean_squared_error, r2_score\n",
    "#import numpy as np\n",
    "\n",
    "df = df[~df['Sector'].str.contains('Sum of all|Final energy consumption', case=False)]\n",
    "df = df[~df['Fuel Type'].str.contains('Sum of all', case=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8376f6db-bea8-45cf-9071-659829ed8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic Label</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUE_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Industry- non energy mining</td>\n",
       "      <td>1990</td>\n",
       "      <td>Bituminous coal</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Industry- non energy mining</td>\n",
       "      <td>1990</td>\n",
       "      <td>Anthracite and manufactured ovoids</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Industry- non energy mining</td>\n",
       "      <td>1990</td>\n",
       "      <td>Coke</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Industry- non energy mining</td>\n",
       "      <td>1990</td>\n",
       "      <td>Lignite</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Fuel Consumption (ktoe)</td>\n",
       "      <td>Industry- non energy mining</td>\n",
       "      <td>1990</td>\n",
       "      <td>Milled peat</td>\n",
       "      <td>ktoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Statistic Label                       Sector  Year  \\\n",
       "2905  Fuel Consumption (ktoe)  Industry- non energy mining  1990   \n",
       "2906  Fuel Consumption (ktoe)  Industry- non energy mining  1990   \n",
       "2907  Fuel Consumption (ktoe)  Industry- non energy mining  1990   \n",
       "2908  Fuel Consumption (ktoe)  Industry- non energy mining  1990   \n",
       "2910  Fuel Consumption (ktoe)  Industry- non energy mining  1990   \n",
       "\n",
       "                               Fuel Type  UNIT  VALUE  VALUE_log  \n",
       "2905                     Bituminous coal  ktoe      0        0.0  \n",
       "2906  Anthracite and manufactured ovoids  ktoe      0        0.0  \n",
       "2907                                Coke  ktoe      0        0.0  \n",
       "2908                             Lignite  ktoe      0        0.0  \n",
       "2910                         Milled peat  ktoe      0        0.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VALUE_log'] = np.log1p(df['VALUE'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9566e7de-e2c2-4f9a-b2de-04132eeff654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X amd y\n",
    "X=df[['Sector', 'Fuel Type', 'Year']]\n",
    "X_encoded = pd.get_dummies(X, columns=['Sector', 'Fuel Type'], drop_first=True)\n",
    "y = df['VALUE_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b7eeaef-5230-435d-9332-ab888d400848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c757ac0a-6621-4946-a1ea-4eff179c7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "param_grids = {\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [10, 20, 30 ],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    \n",
    "    'Random Forest': {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "   # 'learning_rate': [0.01, 0.05, 0.1],\n",
    "    #'subsample': [0.7, 1],\n",
    "    #'colsample_bytree': [0.7, 1]\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9e11c54-22d1-4b5d-84e4-a67eff5b6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "#Store evaluation results\n",
    "results = {\n",
    "    \"R2 Score testing\": {},\n",
    "    \"R2 Score training\": {},\n",
    "    \"MAE\": {},\n",
    "    \"RMSE\": {},\n",
    "    \"CV\": {},\n",
    "    \"CV R2 Mean\": {},    #  Cross-validation R2 mean\n",
    "    \"CV R2 Std\": {}      #  Cross-validation R2 std deviation\n",
    "}\n",
    "predictions = {}\n",
    "best_params = {}\n",
    "fitted_models={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a92a3fbb-a4a6-47c5-ae87-d5dec4ded007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34be4436-8d36-4766-9d2f-badb4b09fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 8\n",
      "Before GridSearchCV CPU usage: 3.9% | Memory usage: 88.2%\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Decision Tree GridSearchCV execution time: 11.99 sec\n",
      "After GridSearchCV CPU usage: 3.3% | Memory usage: 93.1%\n",
      "\n",
      "Decision Tree Best Params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Decision Tree R² Score (Test): 0.910\n",
      "Decision Tree R² Score (Train): 0.965\n",
      "Decision Tree MAE: 1.937\n",
      "Decision Tree RMSE: 16.438\n",
      "Before GridSearchCV CPU usage: 1.0% | Memory usage: 93.1%\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Random Forest GridSearchCV execution time: 302.91 sec\n",
      "After GridSearchCV CPU usage: 0.4% | Memory usage: 89.9%\n",
      "\n",
      "Random Forest Best Params: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Random Forest R² Score (Test): 0.941\n",
      "Random Forest R² Score (Train): 0.983\n",
      "Random Forest MAE: 1.355\n",
      "Random Forest RMSE: 13.299\n"
     ]
    }
   ],
   "source": [
    "#checking memory and cpu usage and execution time for both models\n",
    "#import time\n",
    "#import multiprocessing\n",
    "#import psutil\n",
    "\n",
    "print(\"Number of CPU cores available:\", multiprocessing.cpu_count())\n",
    "\n",
    "# Function to print system usage\n",
    "def print_system_usage(note=\"\"):\n",
    "    cpu = psutil.cpu_percent(interval=1)\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"{note} CPU usage: {cpu}% | Memory usage: {mem.percent}%\")\n",
    "\n",
    "#Train, predict, evaluate\n",
    "for name, model in models.items():\n",
    "       \n",
    "    print_system_usage(\"Before GridSearchCV\")\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], \n",
    "                               cv=5, n_jobs=-1, verbose=1, scoring='r2')\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"{name} GridSearchCV execution time: {end_time - start_time:.2f} sec\")\n",
    "    print_system_usage(\"After GridSearchCV\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params[name] = grid_search.best_params_\n",
    "    #y_pred = best_model.predict(X_test)\n",
    "    # Predict on test set\n",
    "    \n",
    "    y_pred_log = best_model.predict(X_test)\n",
    "    y_trainn=best_model.predict(X_train)\n",
    "\n",
    "    # Invert the log transformation to get predictions in original VALUE scale\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_train_pred = np.expm1(y_trainn)\n",
    "\n",
    "    # Invert y_test as well\n",
    "    y_test_original = np.expm1(y_test)\n",
    "    y_train_original = np.expm1(y_train)\n",
    "    \n",
    "    # Store results\n",
    "    results[\"R2 Score testing\"][name] = r2_score(y_test_original, y_pred)\n",
    "    results[\"R2 Score training\"][name] = r2_score(y_train_original, y_train_pred)\n",
    "    results[\"MAE\"][name] = mean_absolute_error(y_test_original, y_pred)\n",
    "    results[\"RMSE\"][name] = np.sqrt(mean_squared_error(y_test_original, y_pred))\n",
    "    predictions[name] = y_pred\n",
    "\n",
    "    print(f\"\\n{name} Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{name} R² Score (Test): {results['R2 Score testing'][name]:.3f}\")\n",
    "    print(f\"{name} R² Score (Train): {results['R2 Score training'][name]:.3f}\")\n",
    "    print(f\"{name} MAE: {results['MAE'][name]:.3f}\")\n",
    "    print(f\"{name} RMSE: {results['RMSE'][name]:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29f448-2636-4007-b2c9-fdb80d050a5c",
   "metadata": {},
   "source": [
    "Insights: The optimization process using GridSearchCV is computationally efficient for the Decision Tree model, completing 480 fits in just 11.99 seconds with minimal CPU usage (~3.3–3.9%) and moderate memory increase (from 88.2% to 93.1%). In contrast, the Random Forest model, despite performing only 120 fits, requires significantly more time (302.91 seconds) due to its computationally intensive nature, especially with 500 estimators, but interestingly shows lower CPU usage (0.4–1.0%) and memory fluctuation (from 93.1% to 89.9%). This highlights the trade-off between model complexity, resource efficiency, and execution time, where Random Forest offers superior performance metrics but at a higher computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736766c6-d0ee-4bd2-bf38-8de1017cfa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc9393d-d3e4-44f5-a827-5766c6f90b66",
   "metadata": {},
   "source": [
    "# Cross validation with cv=5,10,15 to check the optimized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47472f26-9bfe-49f3-a6b3-9d7a28c5b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a682d10-4cce-405d-b4d6-5369f8521165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 8\n",
      "\n",
      "Running GridSearchCV for Decision Tree ...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running cross_val_score for Decision Tree with cv=5 ...\n",
      "Decision Tree with CV=5: Mean R² = 0.820, Std Dev = 0.030\n",
      "Execution time: 0.27 sec | Avg CPU: 19.8% | Avg Memory: 91.8%\n",
      "\n",
      "Running cross_val_score for Decision Tree with cv=10 ...\n",
      "Decision Tree with CV=10: Mean R² = 0.815, Std Dev = 0.024\n",
      "Execution time: 0.50 sec | Avg CPU: 24.8% | Avg Memory: 90.6%\n",
      "\n",
      "Running cross_val_score for Decision Tree with cv=15 ...\n",
      "Decision Tree with CV=15: Mean R² = 0.808, Std Dev = 0.026\n",
      "Execution time: 0.62 sec | Avg CPU: 34.2% | Avg Memory: 90.6%\n",
      "\n",
      "Running GridSearchCV for Random Forest ...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Running cross_val_score for Random Forest with cv=5 ...\n",
      "Random Forest with CV=5: Mean R² = 0.972, Std Dev = 0.003\n",
      "Execution time: 45.99 sec | Avg CPU: 53.9% | Avg Memory: 90.8%\n",
      "\n",
      "Running cross_val_score for Random Forest with cv=10 ...\n",
      "Random Forest with CV=10: Mean R² = 0.976, Std Dev = 0.003\n",
      "Execution time: 109.86 sec | Avg CPU: 71.9% | Avg Memory: 91.1%\n",
      "\n",
      "Running cross_val_score for Random Forest with cv=15 ...\n",
      "Random Forest with CV=15: Mean R² = 0.976, Std Dev = 0.004\n",
      "Execution time: 141.14 sec | Avg CPU: 95.6% | Avg Memory: 89.5%\n",
      "\n",
      "Summary:\n",
      "           Model  CV  CV R2 Mean  CV R2 Std    Time (s)  Avg CPU (%)  \\\n",
      "0  Decision Tree   5    0.819840   0.030135    0.272547    19.800000   \n",
      "1  Decision Tree  10    0.814818   0.023647    0.504903    24.800000   \n",
      "2  Decision Tree  15    0.807524   0.026316    0.617989    34.200000   \n",
      "3  Random Forest   5    0.972391   0.003328   45.991860    53.858065   \n",
      "4  Random Forest  10    0.975961   0.002867  109.861043    71.902985   \n",
      "5  Random Forest  15    0.976350   0.004019  141.135686    95.588372   \n",
      "\n",
      "   Avg Memory (%)  \n",
      "0       91.800000  \n",
      "1       90.600000  \n",
      "2       90.600000  \n",
      "3       90.838710  \n",
      "4       91.052239  \n",
      "5       89.496512  \n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "#import time #for checking execution time\n",
    "#import multiprocessing #to run multiple processes in parallel, allowing tasks to be executed concurrently using multiple CPU cores.\n",
    "#import psutil #for checking memory and cpu usage\n",
    "#import threading #to create and manage multiple threads within a single process, enabling concurrent execution.\n",
    "#import pandas as pd\n",
    "\n",
    "print(\"Number of CPU cores available:\", multiprocessing.cpu_count())\n",
    "\n",
    "def get_system_usage():\n",
    "    cpu = psutil.cpu_percent(interval=1)\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    return cpu, mem\n",
    "\n",
    "cv_values = [5, 10, 15]\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"CV\": [],\n",
    "    \"CV R2 Mean\": [],\n",
    "    \"CV R2 Std\": [],\n",
    "    \"Time (s)\": [],\n",
    "    \"Avg CPU (%)\": [],\n",
    "    \"Avg Memory (%)\": []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nRunning GridSearchCV for {name} ...\")\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], \n",
    "                               cv=5, n_jobs=-1, verbose=1, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    for cv in cv_values:\n",
    "        kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        print(f\"\\nRunning cross_val_score for {name} with cv={cv} ...\")\n",
    "        \n",
    "        resource_readings = {\"cpu\": [], \"mem\": []}\n",
    "        stop_monitor = threading.Event()\n",
    "\n",
    "        def monitor():\n",
    "            while not stop_monitor.is_set():\n",
    "                cpu, mem = get_system_usage()\n",
    "                resource_readings[\"cpu\"].append(cpu)\n",
    "                resource_readings[\"mem\"].append(mem)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        monitor_thread = threading.Thread(target=monitor)\n",
    "        monitor_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=kf, scoring='r2', n_jobs=-1)\n",
    "        end_time = time.time()\n",
    "\n",
    "        stop_monitor.set()\n",
    "        monitor_thread.join()\n",
    "\n",
    "        avg_cpu = sum(resource_readings[\"cpu\"]) / len(resource_readings[\"cpu\"]) if resource_readings[\"cpu\"] else 0\n",
    "        avg_mem = sum(resource_readings[\"mem\"]) / len(resource_readings[\"mem\"]) if resource_readings[\"mem\"] else 0\n",
    "        exec_time = end_time - start_time\n",
    "\n",
    "        results[\"Model\"].append(name)\n",
    "        results[\"CV\"].append(cv)\n",
    "        results[\"CV R2 Mean\"].append(cv_scores.mean())\n",
    "        results[\"CV R2 Std\"].append(cv_scores.std())\n",
    "        results[\"Time (s)\"].append(exec_time)\n",
    "        results[\"Avg CPU (%)\"].append(avg_cpu)\n",
    "        results[\"Avg Memory (%)\"].append(avg_mem)\n",
    "\n",
    "        print(f\"{name} with CV={cv}: Mean R² = {cv_scores.mean():.3f}, Std Dev = {cv_scores.std():.3f}\")\n",
    "        print(f\"Execution time: {exec_time:.2f} sec | Avg CPU: {avg_cpu:.1f}% | Avg Memory: {avg_mem:.1f}%\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37507f8-32b6-4826-88d9-fc3c3c0a6005",
   "metadata": {},
   "source": [
    "Insights: As cross-validation (CV) folds increases from 5 to 15, both models requires more time and CPU resources. For the Decision Tree, execution time grows from 0.27s to 0.62s, with CPU usage increasing from 19.8% to 34.2%, while memory stays stable (~90–92%), showing efficient scalability. In contrast, the Random Forest model shows significant increases in computational load i.e. time increases sharply from 46s (CV=5) to 141s (CV=15), and average CPU usage surges from 54% to 96%, reflecting its parallel complexity and larger model size.\n",
    "Despite these increases, R² values remained stable for Random Forest, with the Decision Tree slightly declining and the Random Forest consistently achieving high performance across CV folds, thus highlighting the trade-off between improved accuracy and resource demands at higher CV values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c3563-c0d3-4e36-8243-d42a44cba5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be307dbb-6af1-4f72-aa87-6cfec4663b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As checked above, total number of CPU cores available is 8 so we will check execution time with 4 and 8 (max) CPUs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f01521-6182-44cc-8fb8-dfb254574238",
   "metadata": {},
   "source": [
    "# Time optimization with different CPU cores (n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c991659-0665-445e-a42b-6fccd070b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Benchmarking GridSearchCV with cv=5, n_jobs=4\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Execution time: 425.28 sec\n",
      "\n",
      "Random Forest - Benchmarking GridSearchCV with cv=5, n_jobs=-1\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Execution time: 310.13 sec\n"
     ]
    }
   ],
   "source": [
    "# Optimization Benchmarking Section \n",
    "#import time\n",
    "for name, model in models.items():\n",
    "    optimization_configs = [\n",
    "    { \"n_jobs\": 4},\n",
    "    {\"n_jobs\": -1}\n",
    "]\n",
    "\n",
    "for config in optimization_configs:\n",
    "    print(f\"\\n{name} - Benchmarking GridSearchCV with cv=5, n_jobs={config['n_jobs']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_search_opt = GridSearchCV(estimator=model, param_grid=param_grids[name],\n",
    "                                   cv=5, n_jobs=config['n_jobs'], \n",
    "                                   verbose=1, scoring='r2')\n",
    "    grid_search_opt.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Execution time: {end_time - start_time:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "036f3a30-cd82-43af-ae2e-0470e1d15d44",
   "metadata": {},
   "source": [
    "Insights: The above results indicate a trade off between execution time and number of processors used. If 4 CPU cores are used, processor usage is less but execution time is more. But when we increase number of CPU cores (n_jobs = -1 indicates 8 CPU cores), time is reduced. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
